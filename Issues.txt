#!/usr/bin/env python3

import json
import os

def load_results(folder_name):
    """Load results.json from specified folder"""
    path = os.path.join("./output", folder_name, "results.json")
    with open(path, 'r') as f:
        return json.load(f)

def display_table(results, title):
    """Display results as ASCII table"""
    
    # Baseline values
    baseline_mem = 618.7
    baseline_vocab = 1456
    baseline_string = 639984
    
    # Get values
    mem_list = results['memory_mb']
    vocab_list = results['vocab_size']
    string_list = results['string_store_size']
    
    # Batch 1 and Batch 12 values
    batch1_mem = mem_list[0]
    batch12_mem = mem_list[11]  # Index 11 = Batch 12
    
    batch1_vocab = vocab_list[0]
    batch12_vocab = vocab_list[11]
    
    batch1_string = string_list[0]
    batch12_string = string_list[11]
    
    # Total growth
    mem_growth = batch12_mem - baseline_mem
    vocab_growth = batch12_vocab - baseline_vocab
    string_growth = batch12_string - baseline_string
    
    # Range [min, max] for first 12 batches
    mem_range = [min(mem_list[:12]), max(mem_list[:12])]
    vocab_range = [min(vocab_list[:12]), max(vocab_list[:12])]
    string_range = [min(string_list[:12]), max(string_list[:12])]
    
    print(f"\n{'='*100}")
    print(f"{title}")
    print(f"{'='*100}")
    
    # Print table header
    print(f"{'Metric':<20} {'Baseline':<15} {'Batch 1 (Start)':<20} {'Batch 12 (End)':<20} {'Total Growth':<25} {'Range [min,max]':<30}")
    print(f"{'-'*100}")
    
    # Memory row
    print(f"{'Memory (MB)':<20} {f'~{baseline_mem:.1f}':<15} {batch1_mem:<20.2f} {batch12_mem:<20.2f} {f'+{mem_growth:.1f}% (+{mem_growth:.2f} MB)':<25} {f'[{mem_range[0]:.2f}, {mem_range[1]:.2f}]':<30}")
    
    # Vocabulary row
    print(f"{'Vocabulary Size':<20} {baseline_vocab:<15} {batch1_vocab:<20} {batch12_vocab:<20} {f'+{vocab_growth:,} (+{(vocab_growth/baseline_vocab*100):.1f}%)':<25} {f'[{vocab_range[0]:,}, {vocab_range[1]:,}]':<30}")
    
    # String Store row
    print(f"{'String Store Size':<20} {baseline_string:<15} {batch1_string:<20,} {batch12_string:<20,} {f'+{string_growth:,} (+{(string_growth/baseline_string*100):.1f}%)':<25} {f'[{string_range[0]:,}, {string_range[1]:,}]':<30}")
    
    print(f"{'='*100}\n")

def main():
    # Load results from both folders
    results_without = load_results("without_zone")
    results_with = load_results("with_zone")
    
    # Display tables
    display_table(results_without, "WITHOUT Memory Zone (Current Production Behaviour)")
    display_table(results_with, "WITH Memory Zone (Proposed Solution)")

if __name__ == "__main__":
    main()







import pandas as pd
import json
import glob
import os

# Configuration
OUTPUT_DIR = "./output"
COMPARISON_FOLDER = os.path.join(OUTPUT_DIR, "comparison")
NUM_SAMPLES_PER_FILE = 3  # Number of sample rows to show per file

# Get all comparison files
comparison_files = sorted(glob.glob(os.path.join(COMPARISON_FOLDER, "comparison_part_*.csv")))

print(f"Found {len(comparison_files)} comparison files\n")
print("="*100)

# Track statistics
total_non_empty_without = 0
total_non_empty_with = 0
total_comparison_rows = 0

for comp_file in comparison_files[:5]:  # Check first 5 files, adjust as needed
    print(f"\n📁 FILE: {os.path.basename(comp_file)}")
    print("="*100)
    
    # Read comparison file
    df_comp = pd.read_csv(comp_file, low_memory=False)
    total_comparison_rows += len(df_comp)
    
    # Find rows with non-empty JSON (not "[]" and not empty string)
    df_comp['without_has_data'] = df_comp['without_zone_output'].apply(
        lambda x: str(x) not in ['[]', '', 'nan', 'MISSING ROW', 'N/A']
    )
    df_comp['with_has_data'] = df_comp['with_zone_output'].apply(
        lambda x: str(x) not in ['[]', '', 'nan', 'MISSING ROW', 'N/A']
    )
    
    non_empty_rows = df_comp[df_comp['without_has_data'] | df_comp['with_has_data']]
    
    count_without = df_comp['without_has_data'].sum()
    count_with = df_comp['with_has_data'].sum()
    
    total_non_empty_without += count_without
    total_non_empty_with += count_with
    
    print(f"📊 Stats: Total rows={len(df_comp)}, Non-empty without_zone={count_without}, Non-empty with_zone={count_with}")
    print(f"🎯 Match Status: {(df_comp['match_status']=='MATCH').sum()} MATCH, {(df_comp['match_status']=='MISMATCH').sum()} MISMATCH\n")
    
    # Sample rows with actual data
    sample_rows = non_empty_rows.head(NUM_SAMPLES_PER_FILE)
    
    if len(sample_rows) == 0:
        print("⚠️  No rows with data found in this file\n")
        continue
    
    for idx, row in sample_rows.iterrows():
        print(f"\n{'─'*100}")
        print(f"ROW {row.get('row_number', idx)} | Status: {row['match_status']} | ID: {row.iloc[1]}")
        print(f"{'─'*100}")
        
        # Parse and pretty print JSON
        try:
            without_json = json.loads(row['without_zone_output']) if isinstance(row['without_zone_output'], str) else row['without_zone_output']
            without_str = json.dumps(without_json, indent=2, ensure_ascii=False)
        except:
            without_str = str(row['without_zone_output'])
        
        try:
            with_json = json.loads(row['with_zone_output']) if isinstance(row['with_zone_output'], str) else row['with_zone_output']
            with_str = json.dumps(with_json, indent=2, ensure_ascii=False)
        except:
            with_str = str(row['with_zone_output'])
        
        # Split into lines for side-by-side comparison
        without_lines = without_str.split('\n')
        with_lines = with_str.split('\n')
        max_lines = max(len(without_lines), len(with_lines))
        
        print("\n🔵 WITHOUT ZONE" + " "*28 + "🟢 WITH ZONE")
        print("─"*50 + "│" + "─"*49)
        
        for i in range(max_lines):
            left = without_lines[i] if i < len(without_lines) else ""
            right = with_lines[i] if i < len(with_lines) else ""
            print(f"{left:<49}│ {right}")
        
        if row['match_status'] != 'MATCH':
            print(f"\n💬 Comment: {row['comments']}")

print("\n" + "="*100)
print("📈 OVERALL STATISTICS")
print("="*100)
print(f"Total comparison rows checked: {total_comparison_rows:,}")
print(f"Total non-empty without_zone outputs: {total_non_empty_without:,}")
print(f"Total non-empty with_zone outputs: {total_non_empty_with:,}")
print(f"Difference: {abs(total_non_empty_without - total_non_empty_with):,}")

if total_non_empty_without == total_non_empty_with:
    print("✅ Counts match!")
else:
    print("⚠️  Counts don't match - investigate further!")
